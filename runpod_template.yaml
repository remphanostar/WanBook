# RunPod Template for WanGP
name: "WanGP Video Generation"
image: "nvidia/cuda:12.4-devel-ubuntu22.04"
description: "AI Video Generation with WanGP - Text2Video, Image2Video, VACE ControlNet"

# Container configuration
containerDiskInGb: 50
dockerArgs: "--runtime=nvidia"

# Environment variables
env:
  - name: "NVIDIA_VISIBLE_DEVICES"
    value: "all"
  - name: "NVIDIA_DRIVER_CAPABILITIES" 
    value: "compute,utility"

# Ports
ports:
  - containerPort: 7860
    externalPort: 7860
    type: "http"

# Volume mounts
volumeMounts:
  - containerPath: "/workspace"
    volumeSize: 50

# Startup script
startupScript: |
  #!/bin/bash
  cd /workspace
  
  # Install system dependencies
  apt-get update && apt-get install -y \
    python3.10 python3-pip git wget curl ffmpeg \
    libgl1-mesa-glx libglib2.0-0
  
  # Clone repository
  if [ ! -d "Wan2GP" ]; then
    git clone https://github.com/deepbeepmeep/Wan2GP.git
  fi
  
  cd Wan2GP
  
  # Install dependencies
  pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
  pip install -r requirements.txt
  pip install triton sageattention==1.0.6 || true
  
  # Launch WanGP
  python wgp.py --listen --server-port 7860 --share

# Recommended GPU
recommendedGpu: "RTX A5000"
minGpu: "RTX 3080"